+++
title = '藥品消耗量分析：離群與趨勢'
slug = 'consumption-oulier-trend-alert'
date = 2023-09-25T07:45:15+08:00
draft = true
isCJKLanguage = true
showToc = true
TocOpen = true
categories = ['資料視覺化']
math = true
tags = []
+++
之前利用了 python 固定每週彙整出所有藥品的各週消耗量，接著就可以計算每個藥品消耗量的**指標值**，訂出適當的閾值，篩選出指標超過閾值的藥品，形成警示列表。
![Alert-Data-Like](/images/2023-10-alert-data-like.png#center)
***
## 離群值

### 離群值是什麼？
統計上的離群值 (outliers) 指的是超出其類型預期常態的極端數據點，因為各種因素導致的異常數值，例如：輸入錯誤、惡意新增數據、系統異常等等，會嚴重影響統計量的估計值和指標，造成偏差。一般而言，離群值相較於母體或樣本大部分是少數特例，排除後統計量才會比較接近母體或樣本的常態。

在藥品消耗量上，因為消耗量是已經發生過的事實，所以離群值的出現並不是錯誤值，不需要額外排除，反而需要去詳細檢視原因，並且調整往後訂購藥品的計畫。所以針對離群值，反而需要偵測並篩選出來而非排除。

### 偵測離群值
離群值的偵測方法有好幾種，傳統數學的 3 倍標準差法 ( Z 分數法)、箱型圖法，機器學習的 DBSCAN 、 Isolation Forest ，另外對於深度學習也有提出 GANs 等方法來檢測離群值，並且已經成熟到可以應用於產品上，例如心跳離群值的檢測以早期發現疾病等[^1]。

[^1]: [Deep Learning for Anomaly Detection.](https://ff12.fastforwardlabs.com/)

我們需要的是要快速計算出近 1,500 種藥品各 52 週的離群值，由於機器學習或是深度學習都需要先以已經有的資料訓練個別資料的模型，或者是經過一些時間的非監督式學習，才能正式使用在資料上。以現有的需求，機器學習或是深度學習是耗時並且浪費的，所以以傳統數學的方法來檢測藥品消耗量的離群值，並且直接假設所有的消耗量分布都**屬於常態分佈**。

箱型圖法 (Boxplots) 是計算出資料的各四分位數資料後，計算第三四分位數 (Q3) 和第一四分數 (Q1) 的差 (四分位距 IQR) ，如果資料點在臨界四分位數 (Q3 或 Q1) 外 **1.5** 倍的 IQR ，該資料點就是離群值。

例如，假設有一筆資料 `[0, 1, 2, 3, 10, 20, 30, 600, 9000]`，各統計量如下：

![Boxplot Sample](/images/2023-10-boxplot-sample.png#center)

- Q1 = (1+2)/2 = 1.5
- Q2 = 10
- Q3 = (30+600)/2 = 315
- 四分位距 IQR = 315-1.5 = 313.5
- 下限 = 1.5-1.5×313.5 = -468.75
- 上限 = 315+1.5×313.5 = 785.25

也就是說， 9000 這筆資料已經超過了上限 785.25 ，視為該筆資料的離群值。

而標準差法是當資料屬於常態分佈時，資料分布在平均數正負三個標準差內的機率應該為 99.7% ，換句話說，在三個標準差外的可以視為離群值。

![deviation](https://homepage.ntu.edu.tw/~clhsieh/biostatistic/images/deviation.png#center)

一樣的例子，資料 `[0, 1, 2, 3, 10, 20, 30, 600, 9000]`，各統計量如下：
- 平均值 = 1074
- 母體標準差 = 2808.32
- 下限 = 1074-3×2808.32 = -7350.96
- 上限 = 1074+3×2808.32 = 9498.96

該筆資料全部都落在 -7350.96 到 9498.96 之間，沒有離群值。

### 程式實作
實際計算藥品的消耗量後，發現箱形圖法對於離群的容忍範圍比較小，因為篩選出的離群藥品需要透過藥師手動檢核，希望篩選出的離群數量能夠維持在 20~30 個左右，因此選擇了標準差法，而且 3 倍的標準差以外視為離群值的資料量還是過大，微調之後改採用 4 倍標準差。資料區間取一年的每週消耗量，無法很準確的代表最近這幾週的資料，也是經過微調後，僅取後 12 個資料點。但為了避免後續需要再次調整，所以先把閾值變數拉到程式最上面。
```python
import pandas as pd
import numpy as np
# 閾值變數
data_range = 12 # 只取最近的 12 個資料點就好
std_times = 4 # 4 倍標準差以外的視為離群值
```
引入檔案後，整理資料表頭：
```python
# 引入上次的中繼檔案
df = pd.read_csv('暫存.csv')
df = df.iloc[:,-data_range:]
# 原始檔案的 column name 都是日期，重新換成固定的名字 data_x 比較好操作
header = [f'data_{x}' for x in range(0, data_range)]
df = df.set_index('藥品代碼')
df.columns = header
```
排除12個資料都是0的品項，分析沒有意義，也不需要列出警訊：
```python
df = df.loc[df.sum(axis=1)!=0]
```
計算第 1 個到第 11 個的統計值， `.mean()` 和 `.std()` 的預設值都是 `axis=0` 計算直欄的結果，所以要代入 `axis=1` ，而 `.std()` 預設的自由度 `ddof` 是 1 ，也要改成 0 ，因為資料屬於母體總數，而不是抽樣樣本數。
```python
# ppl = population
ppl = [f'data_{x}' for x in range(0, data_range-1)]
df['ppl_mean'] = df[ppl].mean(axis=1)
df['ppl_std'] = df[ppl].std(axis=1, ddof=0)

# 計算上下限
df['upper_std_times'] = df['ppl_mean'] + std_times * df['ppl_std']
df['lower_std_times'] = df['ppl_mean'] - std_times * df['ppl_std']
```
列出大於或小於限制的藥品，並且加入排序依據後輸出 csv 檔：
```python
df.loc[df[f'data_{data_range-1}']>df['upper_std_times'], 'outlier'] = 'greater'
df.loc[df[f'data_{data_range-1}']<df['lower_std_times'], 'outlier'] = 'less'
df['outlier_rate'] = (df[f'data_{data_range-1}']-df['ppl_mean']) / df['ppl_std']
df['outlier_rate'] = df['outlier_rate'].abs().replace(np.inf,np.nan)

df = df.loc[df['outlier'].notna()]
df = df.sort_values(by=['outlier_rate','code'])

df.to_csv('outliers.csv')
```
這個檔案接下來就交給 php 讀取再丟入 chartjs 製圖。
***
## 顯著趨勢
現在的趨勢分析被包含於時間序列資料的數學運算中，建立時間序列的 SARIMAX 模型或是 prophet 模型時，就可以利用數學方法檢測序列的趨勢性，並且利用加性迴歸模型或是乘性迴歸模型進行參數的調整。

問題也跟在檢測離群值的時候一樣，今天的需求是快速的篩選出 1,500 種的藥品，機器學習耗費的效能與時間太多，而且 SARIMAX 模型或是 prophet 模型都還要逐個藥品進行參數的調整，雖然有 Auto-ARIMAX/SARIMAX 這種產品可以自動調整參數，但後來還是決定使用傳統數學的簡單線性迴歸分析來檢查趨勢性。
### 簡單線性迴歸
簡單線性迴歸分析網路上或教科書上可以找到很多很嚴謹的定義，用我自己的話解釋就是，就是找出兩組資料之間的關係。例如說`週序：消耗量`的資料組，分布在二維坐標上，以`週序`為 ${x}$ 軸， ${y}$ 軸是`消耗量`，目標就是畫出一條 ${y=} \beta_0$+$\beta_1 {x}$ 的迴歸直線，找到各個 $\beta$ 。

![簡單線性迴歸分析](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n49Ks_IUMW4ZDXlMxJmjnw.png)

迴歸直線係數的算法就不再贅述了，可以利用高中數學，或是大學數學求得。 Python 也有專門用來進行科學運算的 SciPy 函式庫來計算迴歸直線的各項參數，先把它裝起來：
```powershell
pip install scipy
```
### *p*-value 和 R-squared
另外一個很重要的步驟是檢查這條直線有沒有辦法用來描述資料組，如果直線和資料組的關係很薄弱，表示直線不存在。有兩個統計值可以用來檢查資料組之間和直線的關係，分別是 *p*-value 和 R-squared 。

- ***p*-value** ：用以表達 ${x}$ 軸資料和 ${y}$ 軸資料的關係。當 *p*-value 趨近於 0 時，兩組資料顯著有關，而趨近於 1 時，則不太有關。
- **R-squared** ：用以表達畫出直線與兩組資料的吻合程度。當 R-squared 趨近於 1 時，直線和兩組資料非常吻合，而趨近於 0 時，則不太吻合。

所以目標是要找到 *p*-value 趨近於 0 同時 R-squared 趨近於 1 的資料和迴歸直線，以我們的資料`週序：消耗量`而言，表示消耗量與週序之間相關並且可以找到一條直線描述兩者之間的關係，這條直線又可以說是週序的趨勢直線。

問題來了！我們從機器學習的多參數設計，簡化成傳統數學的線性迴歸，卻還有兩個統計值需要分別建立閾值，還是太多了。還好藥品的資料全部都是母體資料，而且用 *p*-value 和 R-squared 作圖之後發現 *p*-value 趨近於 0 的資料數剛好就是 R-squared 趨近於 1 的資料，如此一來我們只需設定其中一個閾值就好。

<!--![p-value vs R-squared](/images/2023-10-p-value-R-squared.png#center)-->
{{< figure src="/images/2023-10-p-value-R-squared.png" width="65%" alt="p-value vs R-squared" align="center" >}}

> *p*-value 和 R-squared 之間出現矛盾的情形是什麼狀況：
>
>- ***p*-value 不顯著但 R-squared 很吻合**：表示資料組之間不太有關聯性，或者是抽樣的資料組無法代表整體情形，但有可能這次取到的資料點很完美的吻合直線。
>- ***p*-value 很顯著但 R-squared 不吻合**：表示資料組之間關聯性很強，但是迴歸分析的方法可能不是直線，也許是多元直線或是其他曲線。

### 迴歸線與 x 軸的夾角

### 程式實作
***
## 圖表設計
### 離群值
### 顯著趨勢
***
## 成果